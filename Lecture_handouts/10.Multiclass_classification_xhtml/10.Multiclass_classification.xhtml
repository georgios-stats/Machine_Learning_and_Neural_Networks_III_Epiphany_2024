<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta name="GENERATOR" content="LyX 2.3.7" />
<meta http-equiv="Content-type" content="text/html;charset=UTF-8" />
<title>LyX Document</title>
<style type='text/css'>
/* Layout-provided Styles */
div.standard {
text-align: left;

}
div.plain_layout {
text-align: left;

}
h3.subsection_ {
font-weight: bold;
font-size: medium;
margin-top: 0.9ex;
margin-bottom: 0.5ex;
text-align: left;

}
ol.enumerate {
margin-top: 0.7ex;
margin-bottom: 0.7ex;
margin-left: 3ex;
text-align: left;

}
ul.itemize {
margin-top: 0.7ex;
margin-bottom: 0.7ex;
margin-left: 3ex;
text-align: left;

}
div.Shadowbox { border: solid gray medium; border-bottom: solid black 1ex; border-right: solid black 1ex; padding: 0.5ex; }


</style>
</head>
<body dir="auto">


<div class="standard" id='magicparlabel-1'><div class='Shadowbox'><div class="plain_layout" id='magicparlabel-15'>Machine Learning and Neural Networks (MATH3431)&nbsp;&nbsp;Epiphany term, 2024<div style='height:3ex'></div></div>

<div class="plain_layout" style='text-align: center;' id='magicparlabel-16'> Handout <a href="#enu_Handout___Multi_class">enu:Handout-:-Multi-class</a>: Multi-class classification (DRAFT)  <div style='height:3ex'></div></div>

<div class="plain_layout" id='magicparlabel-25'>Lecturer &amp; author: Georgios P. Karagiannis <a href="georgios.karagiannis@durham.ac.uk">georgios.karagiannis@durham.ac.uk</a></div>

<div class="plain_layout" id='magicparlabel-26'><hr />

<div style='height:3ex'></div></div>
<h3 class="subsection_" id='magicparlabel-27'>Aim</h3>
<div class="plain_layout" id='magicparlabel-28'>To introduce the Support Vector Machines as a procedure. Motivation, set-up, description, computation, and implementation. We focus on the classical treatment.</div>

<div class="plain_layout" id='magicparlabel-29'><hr />

<div style='height:3ex'></div></div>
<h3 class="subsection_" id='magicparlabel-30'>Reading list &amp; references:</h3>

<ol class="enumerate" id='magicparlabel-31'><li class="enumerate_item"><a id="enu_Shalev_Shwartz__S____" />
 Shalev-Shwartz, S., &amp; Ben-David, S. (2014). Understanding machine learning: From theory to algorithms. Cambridge university press. 

<ul class="itemize" id='magicparlabel-32'><li class="itemize_item">Ch. 17 (pp. 190-198) </li>
</ul>
</li><li class="enumerate_item">Bishop, C. M. (2006). Pattern recognition and machine learning (Vol. 4, No. 4, p. 738). New York: Springer.

<ul class="itemize" id='magicparlabel-34'><li class="itemize_item">Ch. 7.1 Sparse Kernel Machines/Maximum marginal classifiers </li>
</ul>
</li><li class="enumerate_item">Vapnik, V. (2013). The nature of statistical learning theory. Springer science &amp; business media.</li>
<li class="enumerate_item"><a id="enu_Boyd__S__P__" />
 Boyd, S. P., &amp; Vandenberghe, L. (2004). Convex optimization. Cambridge university press.</li>
<li class="enumerate_item"><a id="enu_Strang__G___2019__" />
 Strang, G. (2019). Linear algebra and learning from data. Wellesley-Cambridge Press.</li>
</ol>
</div></div>


</body>
</html>
